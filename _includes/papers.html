<div class="papers">
    <div class="paper">
        <div class="paper-header">
            <span class="paper-title"><strong>Poster Session</strong></span>
        </div>
        <ul>
            <li>
                <div class="paper-details">
                    <i>Cross-Modal Consistency Learning for Sign Language Recognition</i>
                    <small class="author">Kepeng Wu, Zecheng Li, Weichao Zhao, Hezhen Hu, Wengang Zhou, Houqiang Li</small>
                </div>
            </li>
            <li>
                <div class="paper-details">
                    <i>Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights</i>
                    <small class="author">Tom√°≈° ≈Ωelezn√Ω, Jakub Straka, V√°clav Javorek, Ond≈ôej Valach, Marek Hr√∫z, Ivan Gruber</small>
                </div>
            </li>
        </ul>
    </div>
     <div class="paper">
        <div class="paper-header">
            <span class="paper-title">
                <strong>Remote Papers</strong>
                <small>Pre-recorded Videos and Live Q&A</small>
            </span>
        </div>
        <ul>
            <li>
                <div class="paper-details">
                    <i>Diffusion-Based Continuous Sign Language Generation with Cluster-Specific Fine-Tuning and Motion-Adapted Transformer</i>
                    <small class="author">Razieh Rastgoo, Kourosh Kiani, Sergio Escalera</small>
                </div>
            </li>
            <li>
                <div class="paper-details">
                    <i>BUTID: A Large-scale Sign Language Translation Dataset and Benchmarks for Turkish Sign Language</i>
                    <small class="author">Karahan ≈ûahin, Lale Akarun, Kadir G√∂kg√∂z, Murat Sara√ßlar</small>
                </div>
            </li>
            <li>
                <div class="paper-details">
                    <i>CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign Language Recognition</i>
                    <small class="author">Sarah Alyami, Hamzah Luqman</small>
                </div>
            </li>
        </ul>
    </div>
     <div class="paper">
        <div class="paper-header">
            <span class="paper-title"><strong>Challenge Paper</strong></span>
        </div>
        <ul>
            <li>
                <div class="paper-details">
                    <div class="paper-detail-header">
                        <i>SLRTP2025 Sign Language Production Challenge: Methodology, Results and Future Work</i>
                        <a href="https://openaccess.thecvf.com/content/CVPR2025W/SLRTP/html/Walsh_SLRTP2025_Sign_Language_Production_Challenge_Methodology_Results_and_Future_Work_CVPRW_2025_paper.html" target="_blank" rel="noopener noreferrer">
                            üîó
                        </a>
                    </div>
                    
                    <small class="author">Harry Walsh, Ed Fish, Ozge Mercanoglu Sincan, Mohamed Ilyes Lakhal, Richard Bowden, Neil Fox, Kearsy Cormier, Bencie Woll, Kepeng Wu, Zecheng Li, Weichao Zhao, Haodong Wang, Wengang Zhou, Houqiang Li, Shengeng Tang, Jiayi He, Xu Wang, Ruobei Zhang, Yaxiong Wang, Lechao Cheng, Meryem Tasyurek, Tugce Kiziltepe, Hacer Yalim Keles</small>
                </div>
            </li>
        </ul>
    </div>
</div>
