<div class="papers">
    <div class="paper">
        <div class="paper-header">
            <span class="paper-title"><strong>Poster Session</strong></span>
        </div>
        <ul>
            <li>
                <div class="paper-details">
                    <i>Cross-Modal Consistency Learning for Sign Language Recognition</i>
                    <small class="author">Kepeng Wu, Zecheng Li, Weichao Zhao, Hezhen Hu, Wengang Zhou, Houqiang Li</small>
                </div>
            </li>
            <li>
                <div class="paper-details">
                    <i>Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights</i>
                    <small class="author">Tomáš Železný, Jakub Straka, Václav Javorek, Ondřej Valach, Marek Hrúz, Ivan Gruber</small>
                </div>
            </li>
        </ul>
    </div>
     <div class="paper">
        <div class="paper-header">
            <span class="paper-title">
                <strong>Remote Papers</strong>
                <small>Pre-recorded Videos and Live Q&A</small>
            </span>
        </div>
        <ul>
            <li>
                <div class="paper-details">
                    <i>Diffusion-Based Continuous Sign Language Generation with Cluster-Specific Fine-Tuning and Motion-Adapted Transformer</i>
                    <small class="author">Razieh Rastgoo, Kourosh Kiani, Sergio Escalera</small>
                </div>
            </li>
            <li>
                <div class="paper-details">
                    <i>BUTID: A Large-scale Sign Language Translation Dataset and Benchmarks for Turkish Sign Language</i>
                    <small class="author">Karahan Şahin, Lale Akarun, Kadir Gökgöz, Murat Saraçlar</small>
                </div>
            </li>
            <li>
                <div class="paper-details">
                    <i>CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign Language Recognition</i>
                    <small class="author">Sarah Alyami, Hamzah Luqman</small>
                </div>
            </li>
        </ul>
    </div>
     <div class="paper">
        <div class="paper-header">
            <span class="paper-title"><strong>Challenge Paper</strong></span>
        </div>
        <ul>
            <li>
                <div class="paper-details">
                    <div class="paper-detail-header">
                        <i>SLRTP2025 Sign Language Production Challenge: Methodology, Results and Future Work</i>
                        <a href="https://openaccess.thecvf.com/content/CVPR2025W/SLRTP/html/Walsh_SLRTP2025_Sign_Language_Production_Challenge_Methodology_Results_and_Future_Work_CVPRW_2025_paper.html" target="_blank" rel="noopener noreferrer">
                            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                                <path d="M6 2a1 1 0 0 0-1 1v1h1V3h6v6h-1v1h1a1 1 0 0 0 1-1V3a1 1 0 0 0-1-1H6z"/>
                                <path d="M5 5v6H3V5h2zm8 4h-2v2h2v-2z"/>
                            </svg>
                        </a>
                    </div>
                    
                    <small class="author">Harry Walsh, Ed Fish, Ozge Mercanoglu Sincan, Mohamed Ilyes Lakhal, Richard Bowden, Neil Fox, Kearsy Cormier, Bencie Woll, Kepeng Wu, Zecheng Li, Weichao Zhao, Haodong Wang, Wengang Zhou, Houqiang Li, Shengeng Tang, Jiayi He, Xu Wang, Ruobei Zhang, Yaxiong Wang, Lechao Cheng, Meryem Tasyurek, Tugce Kiziltepe, Hacer Yalim Keles</small>
                </div>
            </li>
        </ul>
    </div>
</div>
